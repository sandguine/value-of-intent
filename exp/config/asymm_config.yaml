# General Experiment Settings
SEED: 30                              # Random seed for reproducibility
NUM_SEEDS: 100                         # Default for hyperparameter tuning (use 100 for adaptability tests)
TRAINING_MODE: standard               # Options: adaptability, standard
AGENT_TYPE: "baseline"                # Options: baseline, oracle
SHARED_POLICY: true                   # Whether to use a shared policy for the agents

# Environment Settings
ENV_NAME: "overcooked"                # Environment used for training
ENV_KWARGS: 
  layout : "forced_coord"         # Overcooked layout (can be overridden during sweeps)

ACTIVATION: "tanh"                    # Activation function for the network (tanh or relu)

# PPO Hyperparameters
LR: 0.0001                            # changed from 2.5e-4 to 0.0001
ANNEAL_LR: true                       # Whether to anneal the learning rate linearly over time
NUM_ENVS: 128                         # Number of parallel environments for sample collection
NUM_STEPS: 128                        # Number of steps per environment before updating the policy
TOTAL_TIMESTEPS: 5e7             # Total timesteps to run the experiment (increased from previous)
UPDATE_EPOCHS: 4                      # Number of update epochs per PPO iteration
NUM_MINIBATCHES: 4                    # Number of minibatches to split each batch during training
GAMMA: 0.98                           # Discount factor for rewards
GAE_LAMBDA: 0.95                      # Lambda for Generalized Advantage Estimation
CLIP_EPS: 0.1                         # Clipping epsilon for PPO
ENT_COEF: 0.01                        # Entropy regularization coefficient (test between 0.01 and 0.05)
VF_COEF: 0.5                          # Coefficient for value function loss
MAX_GRAD_NORM: 0.5                    # Maximum gradient norm for clipping
REW_SHAPING_HORIZON: 2.5e7            # Horizon for reward shaping

# Checkpointing and Results
SAVE_CHECKPOINTS: true                # Whether to save checkpoints periodically
CHECKPOINT_DIR: "checkpoints"         # Directory to save checkpoints
CHECKPOINT_INTERVAL: 10000            # Save checkpoint every 10000 steps
LOAD_CHECKPOINT: false                # Whether to load a checkpoint at the start
CHECKPOINT_PATH: ""                   # Path to the checkpoint file to load (if applicable)

# Results and Metrics
RESULTS_DIR: "results"                # Directory to save results like metrics and learning curves
LOG_INTERVAL: 1000                    # Log metrics every 1000 steps

# WandB Integration
ENTITY: "sandily"                     # WandB entity name (organization or user)
PROJECT: "modular"                    # WandB project name
WANDB_MODE: "online"                  # WandB mode (online, offline, disabled)
